{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulioLaz/Consumer_Spending_Prediction_final/blob/main/Copia_Consumer_Spending_Prediction_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1hBTcO3DUcE"
      },
      "source": [
        "#**PROBLEMA DE NEGOCIO**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0aJ2-45DWYT"
      },
      "source": [
        "La necesidad de prever y optimizar el gasto de sus usuarios ha llevado a una empresa de comercio electrónico a buscar soluciones innovadoras. Como científicos de datos, hemos sido convocados para desarrollar un modelo de machine learning que pueda predecir con precisión cuánto gastará un usuario al visitar dicho sitio web."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-CbolMODc_t"
      },
      "source": [
        "### **Tus tareas principales serán:**\n",
        "\n",
        "**1. Preprocesamiento de Datos:** Importar correctamente y analizar y comprender el conjunto de datos proporcionado, realizar limpieza de datos, eliminar atributos que no aportan valor y manejar valores faltantes.\n",
        "\n",
        "**2. Exploración y Feature Engineering:** Realizar visualizaciones para entender las relaciones entre las variables y seleccionar las características relevantes, identificar variables llaves, codificación de variables categóricas y normalización/escalado de datos.\n",
        "\n",
        "**3. Construcción de Modelos:** Experimentar con algunos algoritmos de machine learning como Linear Regression, Decision Tree Regressor, Random Forest Regressor, entre otros.\n",
        "\n",
        "**4. Evaluación y Selección del Modelo:** Evaluar los modelos utilizando métricas como el error cuadrático medio (MSE), la raíz cuadrada del error cuadrático medio (RMSE) y el coeficiente de determinación (R²). Seleccionar el modelo con el mejor rendimiento para la predicción del gasto de los usuarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSf1O0tt55xO"
      },
      "source": [
        "## Referencia de las variables:\n",
        "https://support.google.com/analytics/answer/3437719?hl=es-419"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYicz3XQPBWp"
      },
      "source": [
        "#**1. Configuración del Ambiente**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C4ALJdhJBaxJ"
      },
      "outputs": [],
      "source": [
        "# !python -V\n",
        "# print('------')\n",
        "# !pip show Pandas | grep 'Name\\|Version'\n",
        "# print('------')\n",
        "# !pip show Matplotlib | grep 'Name\\|Version'\n",
        "\n",
        "# Python 3.10.12\n",
        "# ------\n",
        "# Name: pandas\n",
        "# Version: 1.5.3\n",
        "# ------\n",
        "# Name: matplotlib\n",
        "# Version: 3.7.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "f7V7-iEwRWYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60100303-53c8-430a-e6ec-906d44cda242"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "id": "DU_rDAp0RZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fdeedb-9a06-447b-c139-4c2aff3d0e46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OZd-jJGUPHMD"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "from scipy.stats import randint\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, FunctionTransformer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from joblib import dump, load\n",
        "\n",
        "# Ignorar las advertencias\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Configurar pandas para mostrar todas las columnas\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Variables globales\n",
        "global df_traffic, resultados, modelo, modelo_clasificacion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPkjyKUEWBIt"
      },
      "source": [
        "#**2. Preprocesamiento de Datos**\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X55mq9O8DKcE",
        "outputId": "7c51a148-fb64-4b40-cf31-a3673a234057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vars con valor único (18)\n",
            " ['socialEngagementType', 'browserVersion', 'browserSize', 'operatingSystemVersion', 'mobileDeviceBranding', 'mobileDeviceModel', 'mobileInputSelector', 'mobileDeviceInfo', 'mobileDeviceMarketingName', 'flashVersion', 'language', 'screenColors', 'screenResolution', 'cityId', 'latitude', 'longitude', 'networkLocation', 'visits']\n",
            "La columna 'adwordsClickInfo' contiene valores de tipo dict.\n"
          ]
        }
      ],
      "source": [
        "def preprocesamiento():\n",
        "  global df_traffic\n",
        "  df_traffic = pd.read_csv('https://raw.githubusercontent.com/ElProfeAlejo/Bootcamp_Databases/main/traffic_site.csv', dtype={'date':object,'fullVisitorId':object,'visitId':object})\n",
        "  diccionarios = ['device','geoNetwork','trafficSource','totals']\n",
        "\n",
        "  ## Desempacar diccionario:\n",
        "  for columna in diccionarios:\n",
        "    df_traffic = df_traffic.join(pd.DataFrame([json.loads(linea) for linea in df_traffic[columna]]))\n",
        "  df_traffic.drop(columns=diccionarios, axis=1,inplace=True)\n",
        "\n",
        "  # Convertir las columnas a string para envitar error:\n",
        "  df_traffic_str = df_traffic.astype(str).copy()\n",
        "\n",
        "  # Buscar las columnas que tienen un sólo valor:\n",
        "  unique_value=[]\n",
        "  for col in df_traffic_str.drop(columns='isMobile',axis=1).columns:\n",
        "      if 1 == len(df_traffic_str[col].unique()):\n",
        "        unique_value.append(col)\n",
        "  print(f'Vars con valor único ({len(unique_value)})\\n {unique_value}')\n",
        "\n",
        "  ### eliminar col con valor único:\n",
        "  df_traffic.drop(columns=unique_value,axis=1,inplace=True)\n",
        "\n",
        "  ## Elimino columna con valor un sólo valor\n",
        "  df_traffic.drop(columns='campaignCode',axis=1,inplace=True)\n",
        "\n",
        "  ### cambiar columnas a tipo número:\n",
        "  cuant = ['fullVisitorId','visitId','visitNumber','visitStartTime', 'bounces', 'hits','pageviews','newVisits','pageviews', 'transactionRevenue']\n",
        "  for columna in cuant:\n",
        "      df_traffic[columna] = pd.to_numeric(df_traffic[columna])\n",
        "\n",
        "# ///////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "  ### Analizar si hay alguna tipo dict:\n",
        "  for col in df_traffic.columns:\n",
        "    if isinstance(df_traffic[col].iloc[0], dict):\n",
        "        print(f\"La columna '{col}' contiene valores de tipo dict.\")\n",
        "\n",
        "  ### cambiar valor dentro del dict anterior:\n",
        "  df_traffic['adwordsClickInfo'] = df_traffic['adwordsClickInfo'].apply(lambda x: np.nan if isinstance(x, dict) and x == {'criteriaParameters': 'not available in demo dataset'} else x)\n",
        "\n",
        "  ### Desempacar del dict clave valor:\n",
        "  # Aplicar pd.Series() a la columna 'adwordsClickInfo' para dividir los diccionarios en columnas\n",
        "  expanded_info = df_traffic['adwordsClickInfo'].apply(pd.Series)\n",
        "\n",
        "  # Concatenar el DataFrame original con las nuevas columnas\n",
        "  df_traffic = pd.concat([df_traffic, expanded_info], axis=1)\n",
        "\n",
        "  # Eliminar la columnas:\n",
        "  columns_to_drop = ['adwordsClickInfo', 'criteriaParameters', 0, 'targetingCriteria', 'date']\n",
        "  df_traffic.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "  df_traffic = df_traffic.drop_duplicates() ##eliminar filas duplicadas\n",
        "# ///////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "  ## Cambio formato a visitStartTime:\n",
        "  df_traffic['visitStartTime'] = pd.to_datetime(df_traffic['visitStartTime'], unit='s')\n",
        "\n",
        "  ### cambia los nan a ceros:\n",
        "  df_traffic.fillna(0, inplace=True)\n",
        "\n",
        "  ### Dividir el target en 1e6:\n",
        "  df_traffic['transactionRevenue']= df_traffic['transactionRevenue']/1e6\n",
        "  df_traffic.head(5)\n",
        "\n",
        "preprocesamiento()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4GucSUdpzW9"
      },
      "source": [
        "#**3. Exploración y Feature Engineering**\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7PDefSP3ilYM"
      },
      "outputs": [],
      "source": [
        "def feature_engineering():\n",
        "    global df_traffic\n",
        "    ### Descomponer la columna visitStartTime en columns: año, mes, semana, quincena:\n",
        "    df_traffic['visitStartTime'] = pd.to_datetime(df_traffic['visitStartTime'])\n",
        "\n",
        "    # Crear columnas para el año, el mes, la semana del mes, la quincena del mes y la hora\n",
        "    df_traffic['year'] = df_traffic['visitStartTime'].dt.year.astype('uint16')\n",
        "    df_traffic['month'] = df_traffic['visitStartTime'].dt.month.astype('uint8')\n",
        "    df_traffic['fortnight'] = df_traffic['visitStartTime'].dt.day.apply(lambda day: 1 if day <= 15 else 2).astype('uint8')\n",
        "    df_traffic['hour'] = df_traffic['visitStartTime'].dt.hour.astype('uint8')\n",
        "    df_traffic['day'] = df_traffic['visitStartTime'].dt.day.astype('uint8')\n",
        "    df_traffic['time_range'] = pd.cut(df_traffic['visitStartTime'].dt.hour, bins=[0, 6, 12, 18, 24], labels=['madrugada', 'mañana', 'tarde', 'noche'], ordered=False).astype('object')\n",
        "\n",
        "    ## Elimino col visitStartTime:\n",
        "    df_traffic.drop(columns='visitStartTime', axis=1,inplace=True)\n",
        "\n",
        "    ### Aplicar Codificador de etiquetas para transformar de cualitativa a cuantitativa ordinal:\n",
        "    cualitativas = df_traffic.dtypes[df_traffic.dtypes == object].keys()\n",
        "    for columna in cualitativas:\n",
        "        lbl = LabelEncoder()\n",
        "        strings = list(df_traffic[columna].values.astype('str'))\n",
        "        lbl.fit(strings)\n",
        "        df_traffic[columna] = lbl.transform(strings)\n",
        "        # Convertir al tipo uint8\n",
        "        df_traffic[columna] = df_traffic[columna].astype('uint8')\n",
        "\n",
        "    ## Elimino col sessionId:\n",
        "    df_traffic.drop(columns='sessionId',inplace=True)\n",
        "\n",
        "    ## Codificación de frecuencia:\n",
        "    ### Codificación de Frecuencia:  para fullVisitorId:\n",
        "    fullVisitorId_frequency = df_traffic['fullVisitorId'].value_counts()\n",
        "    df_traffic['fullVisitorId_enc_frec'] = df_traffic['fullVisitorId'].map(fullVisitorId_frequency)\n",
        "\n",
        "    ### Codificación de Frecuencia:  para visitId:\n",
        "    fullVisitorId_frequency = df_traffic['visitId'].value_counts()\n",
        "    df_traffic['visitId_enc_frec'] = df_traffic['visitId'].map(fullVisitorId_frequency)\n",
        "\n",
        "    ### Eliminar visitId, fullVisitorId:\n",
        "    df_traffic.drop(columns='visitId',axis=1,inplace=True)\n",
        "    df_traffic.drop(columns='fullVisitorId',axis=1,inplace=True)\n",
        "\n",
        "    ## convertir a int la col booleana:\n",
        "    df_traffic['isMobile'] = df_traffic['isMobile'].astype(int)\n",
        "\n",
        "    ## cambiar los nan por ceros:\n",
        "    df_traffic.fillna(0, inplace=True)\n",
        "\n",
        "    # Rellenar los valores faltantes en 'transactionRevenue' con cero\n",
        "    df_traffic['transactionRevenue'].fillna(0, inplace=True)\n",
        "\n",
        "    ## Crear nueva col con clasificacion de 0 y 1 para transactionRevenue:\n",
        "    df_traffic['revenue_zero'] = np.where(df_traffic['transactionRevenue'] == 0, 1, 0)\n",
        "\n",
        "    # Codificación one-hot y eliminación de columnas originales\n",
        "    columns=['browser', 'continent','networkDomain']\n",
        "    df_traffic = pd.get_dummies(df_traffic, columns=columns, prefix=columns, drop_first=True)\n",
        "\n",
        "    ### cambiar a frecuencias:\n",
        "    columns_to_map = ['city', 'country', 'subContinent', 'metro','hour','time_range','channelGrouping']\n",
        "\n",
        "    for column in columns_to_map:\n",
        "        column_frequency = df_traffic[column].value_counts()\n",
        "        df_traffic[column] = df_traffic[column].map(column_frequency)\n",
        "\n",
        "    #### Eliminar columnas;\n",
        "    columns_features= ['year','fortnight','isMobile','campaign','gclId',\n",
        "                       'page', 'adContent','bounces','newVisits',\n",
        "                       'metro','visitId_enc_frec','browser_1','browser_2',\n",
        "                      'browser_3',\t'browser_4',\t'browser_6',\t'browser_7'] ### ,'gclId','page'\n",
        "    for feature in columns_features:\n",
        "        df_traffic.drop(columns=[feature], inplace=True)\n",
        "\n",
        "    df_traffic.drop(columns=['isVideoAd', 'adNetworkType','slot','hits'],axis=1,inplace=True)\n",
        "\n",
        "    ### optimize memory\n",
        "    conversion_dict = {\n",
        "        'transactionRevenue': 'uint16',\n",
        "        'channelGrouping': 'uint16',\n",
        "        'subContinent': 'uint16',\n",
        "        'country': 'uint16',\n",
        "        'city': 'uint16',\n",
        "        'hour': 'uint16',\n",
        "        'time_range': 'uint16',\n",
        "        'fullVisitorId_enc_frec': 'uint8',\n",
        "        'visitNumber': 'uint8',\n",
        "        'revenue_zero': 'uint8',\n",
        "        'pageviews': 'uint16'\n",
        "    }\n",
        "    df_traffic = df_traffic.astype(conversion_dict)\n",
        "\n",
        "feature_engineering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRH2u-dX7WzM"
      },
      "source": [
        "#**4. Construcción de Modelos**\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crea_modelos():\n",
        "\n",
        "    data_traf=df_traffic.copy()\n",
        "    X = data_traf.drop('transactionRevenue',axis=1)\n",
        "    y = data_traf.transactionRevenue.copy()\n",
        "\n",
        "    ### Separar en bases de entrenamiento y prueba:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)\n",
        "\n",
        "    # Crea una instancia de StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Ajusta el escalador a tus datos de entrenamiento\n",
        "    scaler.fit(X_train)\n",
        "    X_train_scaled = scaler.transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    ### MODELS  ###\n",
        "    #  RandomForestRegressor\n",
        "    #  LGBMRegressor\n",
        "    #  XGBRegressor\n",
        "    #  XGB\n",
        "\n",
        "    random_forest_regressor = RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_split=10, min_samples_leaf=4)\n",
        "    lgbm_regressor = LGBMRegressor(n_estimators=165, max_depth=10, learning_rate=0.1, min_child_samples=10)\n",
        "    xgb_regressor = XGBRegressor(n_estimators=140, max_depth=10, learning_rate=0.1, min_child_weight=10)\n",
        "\n",
        "    # Entrenar los modelos con los datos\n",
        "    random_forest_regressor.fit(X_train_scaled, y_train)\n",
        "    lgbm_regressor.fit(X_train, y_train)\n",
        "    xgb_regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Hacer predicciones con los modelos entrenados\n",
        "    y_pred_random_forest = random_forest_regressor.predict(X_test_scaled)\n",
        "    y_pred_lgbm = lgbm_regressor.predict(X_test)\n",
        "    y_pred_xgb = xgb_regressor.predict(X_test)\n",
        "\n",
        "    # Evaluar los modelos\n",
        "    rmse_random_forest = mean_squared_error(y_test, y_pred_random_forest, squared=False)\n",
        "    rmse_lgbm = mean_squared_error(y_test, y_pred_lgbm, squared=False)\n",
        "    rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
        "\n",
        "    r2_random_forest = r2_score(y_test, y_pred_random_forest)\n",
        "    r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
        "    r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "    ################################################################\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "    # Definir los parámetros del modelo\n",
        "    params_xgb = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'rmse',\n",
        "        'max_depth': 6,\n",
        "        'eta': 0.05,\n",
        "        'subsample': 0.91,\n",
        "        'colsample_bytree': 0.81,\n",
        "        'seed': 42\n",
        "    }\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    num_round = 900  # Número de iteraciones\n",
        "    bst = xgb.train(params_xgb, dtrain, num_round, evals=[(dtest, 'eval')], early_stopping_rounds=18)\n",
        "\n",
        "    # Hacer predicciones en el conjunto de prueba\n",
        "    y_pred = bst.predict(dtest)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    ################################################################\n",
        "    print(\"Resultados de los Modelos Adicionales:\")\n",
        "    print(f\"Random Forest Regressor - R-cuadrado (R²): {r2_random_forest:.2%}, RMSE: {rmse_random_forest:.2f}\")\n",
        "    print(f\"LightGBM Regressor - R-cuadrado (R²): {r2_lgbm:.2%}, RMSE: {rmse_lgbm:.2f}\")\n",
        "    print(f\"XGBoost Regressor - R-cuadrado (R²): {r2_xgb:.2%}, RMSE: {rmse_xgb:.2f}\")\n",
        "    print(f\"XGB - R-cuadrado (R²): {r2:.2%}, RMSE: {rmse:.2f}\")"
      ],
      "metadata": {
        "id": "n0ZDY7cXNYUK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crea_modelos()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m39fBRYbVzmE",
        "outputId": "833f9448-fd0c-414c-a1ff-4b8b9bc17512"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003273 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1063\n",
            "[LightGBM] [Info] Number of data points in the train set: 9826, number of used features: 204\n",
            "[LightGBM] [Info] Start training from score 1.480256\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[0]\teval-rmse:20.20259\n",
            "[1]\teval-rmse:20.18937\n",
            "[2]\teval-rmse:20.03733\n",
            "[3]\teval-rmse:19.67091\n",
            "[4]\teval-rmse:19.21404\n",
            "[5]\teval-rmse:18.84813\n",
            "[6]\teval-rmse:18.59248\n",
            "[7]\teval-rmse:18.44395\n",
            "[8]\teval-rmse:18.29335\n",
            "[9]\teval-rmse:18.21222\n",
            "[10]\teval-rmse:17.70104\n",
            "[11]\teval-rmse:17.36419\n",
            "[12]\teval-rmse:17.07507\n",
            "[13]\teval-rmse:16.94660\n",
            "[14]\teval-rmse:16.76920\n",
            "[15]\teval-rmse:16.74981\n",
            "[16]\teval-rmse:16.51668\n",
            "[17]\teval-rmse:16.20364\n",
            "[18]\teval-rmse:16.11670\n",
            "[19]\teval-rmse:15.87760\n",
            "[20]\teval-rmse:15.67497\n",
            "[21]\teval-rmse:15.48008\n",
            "[22]\teval-rmse:15.20711\n",
            "[23]\teval-rmse:14.93635\n",
            "[24]\teval-rmse:14.77145\n",
            "[25]\teval-rmse:14.52425\n",
            "[26]\teval-rmse:14.51134\n",
            "[27]\teval-rmse:14.53766\n",
            "[28]\teval-rmse:14.53319\n",
            "[29]\teval-rmse:14.26957\n",
            "[30]\teval-rmse:14.12003\n",
            "[31]\teval-rmse:13.97629\n",
            "[32]\teval-rmse:13.74116\n",
            "[33]\teval-rmse:13.60495\n",
            "[34]\teval-rmse:13.58326\n",
            "[35]\teval-rmse:13.49164\n",
            "[36]\teval-rmse:13.48459\n",
            "[37]\teval-rmse:13.33264\n",
            "[38]\teval-rmse:13.26832\n",
            "[39]\teval-rmse:13.17915\n",
            "[40]\teval-rmse:13.03842\n",
            "[41]\teval-rmse:12.95568\n",
            "[42]\teval-rmse:12.95187\n",
            "[43]\teval-rmse:12.85444\n",
            "[44]\teval-rmse:12.68429\n",
            "[45]\teval-rmse:12.56197\n",
            "[46]\teval-rmse:12.47055\n",
            "[47]\teval-rmse:12.45399\n",
            "[48]\teval-rmse:12.32880\n",
            "[49]\teval-rmse:12.22045\n",
            "[50]\teval-rmse:12.18021\n",
            "[51]\teval-rmse:12.07634\n",
            "[52]\teval-rmse:12.01800\n",
            "[53]\teval-rmse:12.00175\n",
            "[54]\teval-rmse:11.90188\n",
            "[55]\teval-rmse:11.87584\n",
            "[56]\teval-rmse:11.77584\n",
            "[57]\teval-rmse:11.75409\n",
            "[58]\teval-rmse:11.69922\n",
            "[59]\teval-rmse:11.64390\n",
            "[60]\teval-rmse:11.61845\n",
            "[61]\teval-rmse:11.61375\n",
            "[62]\teval-rmse:11.54383\n",
            "[63]\teval-rmse:11.56356\n",
            "[64]\teval-rmse:11.51799\n",
            "[65]\teval-rmse:11.51498\n",
            "[66]\teval-rmse:11.48089\n",
            "[67]\teval-rmse:11.42649\n",
            "[68]\teval-rmse:11.37955\n",
            "[69]\teval-rmse:11.38035\n",
            "[70]\teval-rmse:11.36241\n",
            "[71]\teval-rmse:11.32291\n",
            "[72]\teval-rmse:11.26349\n",
            "[73]\teval-rmse:11.24031\n",
            "[74]\teval-rmse:11.19195\n",
            "[75]\teval-rmse:11.19091\n",
            "[76]\teval-rmse:11.19018\n",
            "[77]\teval-rmse:11.18844\n",
            "[78]\teval-rmse:11.18824\n",
            "[79]\teval-rmse:11.18627\n",
            "[80]\teval-rmse:11.18627\n",
            "[81]\teval-rmse:11.16830\n",
            "[82]\teval-rmse:11.16610\n",
            "[83]\teval-rmse:11.13500\n",
            "[84]\teval-rmse:11.11903\n",
            "[85]\teval-rmse:11.06245\n",
            "[86]\teval-rmse:11.06380\n",
            "[87]\teval-rmse:11.05538\n",
            "[88]\teval-rmse:11.06124\n",
            "[89]\teval-rmse:11.04381\n",
            "[90]\teval-rmse:11.05480\n",
            "[91]\teval-rmse:10.98956\n",
            "[92]\teval-rmse:10.98577\n",
            "[93]\teval-rmse:10.98772\n",
            "[94]\teval-rmse:10.94352\n",
            "[95]\teval-rmse:10.91712\n",
            "[96]\teval-rmse:10.90208\n",
            "[97]\teval-rmse:10.87158\n",
            "[98]\teval-rmse:10.88049\n",
            "[99]\teval-rmse:10.85658\n",
            "[100]\teval-rmse:10.84083\n",
            "[101]\teval-rmse:10.85853\n",
            "[102]\teval-rmse:10.85317\n",
            "[103]\teval-rmse:10.85256\n",
            "[104]\teval-rmse:10.86130\n",
            "[105]\teval-rmse:10.86964\n",
            "[106]\teval-rmse:10.86645\n",
            "[107]\teval-rmse:10.87257\n",
            "[108]\teval-rmse:10.87159\n",
            "[109]\teval-rmse:10.86882\n",
            "[110]\teval-rmse:10.88443\n",
            "[111]\teval-rmse:10.88479\n",
            "[112]\teval-rmse:10.89224\n",
            "[113]\teval-rmse:10.87457\n",
            "[114]\teval-rmse:10.87691\n",
            "[115]\teval-rmse:10.87504\n",
            "[116]\teval-rmse:10.88515\n",
            "[117]\teval-rmse:10.86368\n",
            "[118]\teval-rmse:10.86878\n",
            "Resultados de los Modelos Adicionales:\n",
            "Random Forest Regressor - R-cuadrado (R²): 57.30%, RMSE: 13.52\n",
            "LightGBM Regressor - R-cuadrado (R²): 65.36%, RMSE: 12.18\n",
            "XGBoost Regressor - R-cuadrado (R²): 71.00%, RMSE: 11.14\n",
            "XGB - R-cuadrado (R²): 72.40%, RMSE: 10.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def modelos_new():\n",
        "    data_traf = df_traffic.copy()\n",
        "    X = data_traf.drop('transactionRevenue', axis=1)\n",
        "    y = data_traf.transactionRevenue.copy()\n",
        "\n",
        "    # Separar en bases de entrenamiento y prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "    # Escalar los datos\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train_scaled = scaler.transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    random_forest_regressor = RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_split=10, min_samples_leaf=4)\n",
        "    lgbm_regressor = LGBMRegressor(n_estimators=200, max_depth=10, learning_rate=0.1, min_child_samples=10)\n",
        "    xgb_regressor = XGBRegressor(n_estimators=200, max_depth=10, learning_rate=0.1, min_child_weight=10)\n",
        "\n",
        "    # Entrenar y evaluar modelos de manera independiente\n",
        "    random_forest_regressor.fit(X_train_scaled, y_train)\n",
        "    lgbm_regressor.fit(X_train, y_train)\n",
        "    xgb_regressor.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_random_forest = random_forest_regressor.predict(X_test_scaled)\n",
        "    y_pred_lgbm = lgbm_regressor.predict(X_test)\n",
        "    y_pred_xgb = xgb_regressor.predict(X_test)\n",
        "\n",
        "    rmse_random_forest = mean_squared_error(y_test, y_pred_random_forest, squared=False)\n",
        "    rmse_lgbm = mean_squared_error(y_test, y_pred_lgbm, squared=False)\n",
        "    rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
        "\n",
        "    r2_random_forest = r2_score(y_test, y_pred_random_forest)\n",
        "    r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
        "    r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "    # Realizar validación cruzada para XGBoost\n",
        "    params_xgb = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'rmse',\n",
        "        'max_depth': 10,\n",
        "        'eta': 0.1,\n",
        "        'subsample': 0.91,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'seed': 42\n",
        "    }\n",
        "\n",
        "    dall = xgb.DMatrix(X, label=y)\n",
        "    cv_results = xgb.cv(params_xgb, dall, num_boost_round=1000, nfold=5, metrics='rmse', early_stopping_rounds=10, seed=42)\n",
        "    best_num_round = cv_results['test-rmse-mean'].idxmin()\n",
        "    bst_new = xgb.train(params_xgb, dall, num_boost_round=best_num_round)\n",
        "    y_pred_new = bst_new.predict(xgb.DMatrix(X_test))\n",
        "\n",
        "    rmse_new = mean_squared_error(y_test, y_pred_new, squared=False)\n",
        "    r2_new = r2_score(y_test, y_pred_new)\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(\"Resultados de los Modelos Adicionales:\")\n",
        "    print(f\"Random Forest Regressor - R²: {r2_random_forest:.2%}, RMSE: {rmse_random_forest:.2f}\")\n",
        "    print(f\"LightGBM Regressor - R²: {r2_lgbm:.2%}, RMSE: {rmse_lgbm:.2f}\")\n",
        "    print(f\"XGBoost Regressor - R²: {r2_xgb:.2%}, RMSE: {rmse_xgb:.2f}\")\n",
        "    print(f\"XGB DMatrix - R²: {r2_new:.2%}, RMSE: {rmse_new:.2f}\")\n"
      ],
      "metadata": {
        "id": "WwSX5ArXgXP4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelos_new()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-AxmhKchnRg",
        "outputId": "02d6b89d-5baa-49e0-e8ec-6c2627012ed0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1063\n",
            "[LightGBM] [Info] Number of data points in the train set: 9826, number of used features: 204\n",
            "[LightGBM] [Info] Start training from score 1.480256\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Resultados de los Modelos Adicionales:\n",
            "Random Forest Regressor - R²: 57.09%, RMSE: 13.55\n",
            "LightGBM Regressor - R²: 65.14%, RMSE: 12.22\n",
            "XGBoost Regressor - R²: 69.85%, RMSE: 11.36\n",
            "XGB DMatrix - R²: 99.98%, RMSE: 0.29\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OYicz3XQPBWp",
        "7y5Llo_mx9Cz",
        "jcSLZs21QeUk"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}